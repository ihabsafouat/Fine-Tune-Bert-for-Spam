# ğŸ“§ Smart Anti-Spam System

A full-stack spam email classifier using BERT (Fine-tuned `bert-base-uncased`) with a React frontend and FastAPI backend.

## ğŸ—ï¸ Project Structure

```
PCyber/
â”œâ”€â”€ backend/                 # FastAPI Backend
â”‚   â”œâ”€â”€ api/                # API endpoints (future expansion)
â”‚   â”‚   â”œâ”€â”€ database.py     # SQLAlchemy setup
â”‚   â”‚   â””â”€â”€ init_db.py      # Database initialization
â”‚   â”œâ”€â”€ models/             # Database models
â”‚   â”‚   â””â”€â”€ models.py       # User and Email models
â”‚   â”œâ”€â”€ services/           # Business logic services
â”‚   â”‚   â”œâ”€â”€ email_processor.py      # Email processing
â”‚   â”‚   â””â”€â”€ sendmail_integration.py # Email delivery
â”‚   â”œâ”€â”€ ml/                 # Machine Learning components
â”‚   â”‚   â””â”€â”€ model_loader.py # BERT model loading and prediction
â”‚   â””â”€â”€ app.py              # Main FastAPI application
â”œâ”€â”€ frontend/               # React Frontend (Vite + TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â”œâ”€â”€ services/       # API services
â”‚   â”‚   â”œâ”€â”€ contexts/       # React contexts
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                   # Dataset files
â”‚   â”œâ”€â”€ train.parquet       # Training data
â”‚   â”œâ”€â”€ test.parquet        # Test data
â”‚   â””â”€â”€ spam.csv            # Spam dataset
â”œâ”€â”€ content/                # ML Model files
â”‚   â””â”€â”€ best_model/         # Trained BERT model
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”‚   â””â”€â”€ Final_Code.ipynb    # BERT fine-tuning notebook
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ alembic/            # Database migrations
â”‚   â””â”€â”€ alembic.ini         # Alembic configuration
â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â””â”€â”€ entrypoint.sh       # Docker entrypoint
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ mail/                   # Email processing
â”œâ”€â”€ main.py                 # Application entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ Dockerfile              # Docker configuration
â”œâ”€â”€ docker-compose.yaml     # Docker Compose setup
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Node.js 16+
- Docker & Docker Compose (optional)

### Option 1: Using Docker (Recommended)

1. **Clone and navigate to the project:**
   ```bash
   cd PCyber
   ```

2. **Start the application:**
   ```bash
   docker-compose up --build
   ```

3. **Access the application:**
   - Backend API: http://localhost:8000
   - Frontend: http://localhost:5173 (run separately)
   - API Documentation: http://localhost:8000/docs

### Option 2: Local Development

1. **Backend Setup:**
   ```bash
   # Create virtual environment
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   
   # Install dependencies
   pip install -r requirements.txt
   
   # Run backend
   python main.py
   ```

2. **Frontend Setup:**
   ```bash
   cd frontend
   npm install
   npm run dev
   ```

## ğŸ“Š ML Model Performance

The fine-tuned BERT model achieves excellent performance:

| Metric | Value |
|--------|-------|
| Accuracy | 99.78% |
| Precision | 99.85% |
| Recall | 99.71% |
| F1-Score | 99.00% |

## ğŸ”§ API Endpoints

- `POST /api/v1/signup` - User registration
- `POST /api/v1/login` - User authentication
- `POST /api/v1/send-email` - Send email with spam detection
- `GET /api/v1/emails/sent` - Get sent emails
- `GET /api/v1/emails/received` - Get received emails
- `GET /api/v1/emails/spam` - Get spam emails
- `GET /api/v1/health` - Health check

## ğŸ› ï¸ Technologies Used

### Backend
- **FastAPI** - Modern Python web framework
- **SQLAlchemy** - Database ORM
- **Alembic** - Database migrations
- **BERT (Hugging Face)** - ML model for spam detection
- **Sendmail** - Email delivery integration
- **JWT** - Authentication

### Frontend
- **React** - UI framework
- **TypeScript** - Type safety
- **Vite** - Build tool
- **Tailwind CSS** - Styling
- **Spline** - 3D background
- **Axios** - HTTP client

### Infrastructure
- **Docker** - Containerization
- **PostgreSQL** - Database
- **SQLite** - Development database

## ğŸ“ Development

### Database Migrations
```bash
# Create new migration
alembic revision --autogenerate -m "Description"

# Apply migrations
alembic upgrade head
```

### ML Model Training
See `notebooks/Final_Code.ipynb` for the complete BERT fine-tuning process.

## ğŸ“„ License

This project is for educational and research purposes.

---

## ğŸ“ Dataset

- **train.parquet**: 8,180 emails  
- **test.parquet**: 2,170 emails  

Each row contains:
- `text`: Email content  
- `label`: `0 = not spam`, `1 = spam`

---

## ğŸ›  Features

- Fine-tunes `bert-base-uncased` for binary classification
- Uses 5-fold Stratified K-Fold Cross-Validation
- Evaluates using accuracy, precision, recall, and F1-score
- Logs metrics (optional) with Weights & Biases (W&B)
- Saves the best model and evaluates it on the test set

---

<br/>
<br/>


## ğŸ“ˆ Evaluation

Used cross-validation and accuracy/F1-score.

| Model              | Accuracy |
|--------------------|----------|
| eval_loss          | 0.0109   |
| eval_accuracy      | 0.9978   |
| eval_precision     | 0.9985   |
| eval_recall        | 0.9971   |
| eval_f1            | 0.99     |


<br/>
<br/>

## ğŸ“‹ Classification Report

          precision    recall  f1-score   support

       0       1.00      1.00      1.00      1350
       1       1.00      1.00      1.00      1375

accuracy                           1.00      2725


<br/>
<br/>

## ğŸ§  Learnings

- BERT is highly effective for binary classification tasks such as spam detection.
- Using **Stratified K-Fold Cross-Validation** helped ensure that each fold maintained the class balance, leading to more reliable model performance across different data splits.
- Hugging Face's `Trainer` API simplifies training, evaluation, and integration of transformers models.
- Tokenizing text inputs with correct padding and truncation is critical to prevent shape mismatches and runtime errors.
- The evaluation metrics show that the model generalizes very well and has minimal overfitting.
- Disabling external tools like W&B during development helps reduce unnecessary overhead when experimenting locally.
- Managing `label` types carefully (e.g., converting to `int64`) is important when working with PyTorch tensors.


<br/>
<br/>


## ğŸš€ How to Run

### 1. Install Dependencies

```bash
pip install -r requirements.txt
